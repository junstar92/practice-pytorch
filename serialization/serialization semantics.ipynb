{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95d814ca-d69d-4718-a155-32c204d1553e",
   "metadata": {},
   "source": [
    "- Reference: [Serialization Semantics](https://pytorch.org/docs/stable/notes/serialization.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec08657-e127-41f4-bf32-1d0d14143fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db264b8-7627-4a41-8e8e-9fa74eeba5b1",
   "metadata": {},
   "source": [
    "# Saving and loading tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1f275ba-f283-47e6-b5cb-60956bf7fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'torch.save()' and 'torch.load()' let you easily save and load tensors:\n",
    "\n",
    "t = torch.tensor([1., 2.])\n",
    "torch.save(t, 'tensor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d0e2f97-2a85-440c-9928-4c4b782c3bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('tensor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd372efc-c81e-476f-ac17-cb222bcc673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'torch.save()' and 'torch.load()' use Python's pickle by default,\n",
    "# so you can also save multiple tensors as part of Python objects like tuples, lists, and dicts:\n",
    "d = {'a': torch.tensor([1., 2.]), 'b': torch.tensor([3., 4.])}\n",
    "torch.save(d, 'tensor_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d01395f0-5b2d-459b-a48e-8a7d9d85b5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': tensor([1., 2.]), 'b': tensor([3., 4.])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('tensor_dict.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651c3974-18ed-42bf-8a59-617a069233d6",
   "metadata": {},
   "source": [
    "# Saving and loading tensors preserves views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be061762-32ff-46cd-ba8c-466614efd11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = torch.arange(1, 10)\n",
    "evens = numbers[1::2]\n",
    "\n",
    "torch.save([numbers, evens], 'tensors.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d22822de-76f6-4741-86af-e3381b2ed3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  4,  3,  8,  5, 12,  7, 16,  9])\n"
     ]
    }
   ],
   "source": [
    "# Saving tensors preserve their view relationship\n",
    "# Behind the scenes, these tensors share the same \"storage\"\n",
    "loaded_numbers, loaded_evens = torch.load('tensors.pt')\n",
    "loaded_evens *= 2\n",
    "print(loaded_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17288b38-08ac-4f1b-b6cf-bab133559b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In some caees, however, saving the current storage objects may be unnecessary and\n",
    "# create prohibitively large files.\n",
    "# In the folloing snippet a storage must larger than saved tensor is written to a file:\n",
    "large = torch.arange(1, 1000)\n",
    "small = large[0:5]\n",
    "\n",
    "torch.save(small, 'small.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdbb612c-72fd-45f2-aaa6-904621fe5116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/77/4ggz4lw57j56q3rwbn52hkdw0000gn/T/ipykernel_3275/681783225.py:2: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  print(loaded_small.storage().size())\n"
     ]
    }
   ],
   "source": [
    "loaded_small = torch.load('small.pt')\n",
    "print(loaded_small.storage().size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13b17872-179e-4414-9b49-c774f79ede2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When saving tensors with fewer elements than their storage objects,\n",
    "# the size of the svaed file can be reduced by first cloning the tensors.\n",
    "torch.save(small.clone(), 'small.pt') # saves a clone of small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36333159-fa12-4513-80e8-12cf74598107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "loaded_small = torch.load('small.pt')\n",
    "print(loaded_small.storage().size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d695c1e-266e-4cc4-bc79-a3824ee87dc0",
   "metadata": {},
   "source": [
    "# Saving and loading torch.nn.Modules\n",
    "\n",
    "- see also: [Saving and Loading Models](https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n",
    "\n",
    "In PyTorch, a module's state is frequently serialized using a 'state dict'. A module's state dict contains all of its parameters and persistent buffers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efefd857-6af2-4103-b748-e2e257841857",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = torch.nn.BatchNorm1d(3, track_running_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6332e87a-2dab-4f74-a65a-121188a7ee11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight',\n",
       "  Parameter containing:\n",
       "  tensor([1., 1., 1.], requires_grad=True)),\n",
       " ('bias',\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0.], requires_grad=True))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bn.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85026090-6dc7-40e2-95e6-3a037392cbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('running_mean', tensor([0., 0., 0.])),\n",
       " ('running_var', tensor([1., 1., 1.])),\n",
       " ('num_batches_tracked', tensor(0))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bn.named_buffers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac3ccc8e-8adb-49d5-a4f8-be5a7d96b2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([1., 1., 1.])),\n",
       "             ('bias', tensor([0., 0., 0.])),\n",
       "             ('running_mean', tensor([0., 0., 0.])),\n",
       "             ('running_var', tensor([1., 1., 1.])),\n",
       "             ('num_batches_tracked', tensor(0))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd302409-fb65-4342-aaaf-b05ab46ec641",
   "metadata": {},
   "source": [
    "Instead of saving a module directly, for compatibility reasons it is recommended to instead save only its state dict. Python modules even have a function, `load_state_dict()`, to restore their states from a state dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33af741e-05a9-4295-821a-e9e79e2c1306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(bn.state_dict(), 'bn.pt')\n",
    "bn_state_dict = torch.load('bn.pt')\n",
    "new_bn = torch.nn.BatchNorm1d(3, track_running_stats=True)\n",
    "new_bn.load_state_dict(bn_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b58ed83-c305-4139-8aa4-450573bb4e57",
   "metadata": {},
   "source": [
    "Even custom modules and modules containing other modules have state dicts and can use this pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15ed0089-b47f-4e64-b19f-0a5f766d521e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('l0.weight', tensor([[ 0.4830,  0.2238, -0.3981,  0.0723],\n",
      "        [ 0.2290, -0.3365, -0.2250,  0.0290]])), ('l0.bias', tensor([-0.0201,  0.2434])), ('l1.weight', tensor([[-0.1918,  0.5304]])), ('l1.bias', tensor([-0.2418]))])\n"
     ]
    }
   ],
   "source": [
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l0 = torch.nn.Linear(4, 2)\n",
    "        self.l1 = torch.nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.l0(input)\n",
    "        out_relu = torch.nn.functional.relu(out)\n",
    "        return self.l1(out_relu)\n",
    "\n",
    "m = MyModule()\n",
    "print(m.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee2df8cd-19d1-49c2-bf21-b68ec971e455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(m.state_dict(), 'mymodule.pt')\n",
    "m_state_dict = torch.load('mymodule.pt')\n",
    "new_m = MyModule()\n",
    "new_m.load_state_dict(m_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e89f8-b285-4d5e-90e9-d4cc7b7d6ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
